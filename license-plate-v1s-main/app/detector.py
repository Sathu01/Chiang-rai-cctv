import cv2
import json
from pathlib import Path
from ultralytics import YOLO
from datetime import datetime
import numpy as np
from typing import Optional, Dict, List
import time
import logging
from PIL import Image, ImageDraw, ImageFont

# Import Gemini OCR
try:
    from gemini import GeminiOCR
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è Gemini OCR not available")

from config import settings

logger = logging.getLogger(__name__)

class LicensePlateDetector:
    """
    ‡∏ï‡∏±‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    
    Components:
    1. YOLO Model - ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡πâ‡∏≤‡∏¢ (‡∏à‡∏≤‡∏Å morsetechlab)
    2. Gemini OCR - ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏õ‡πâ‡∏≤‡∏¢
    
    Usage:
        detector = LicensePlateDetector()
        result = detector.detect("input/car.jpg")
        print(result['detections'][0]['ocr']['text'])
    """
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        conf_threshold: Optional[float] = None,
        use_gemini: bool = True,
        gemini_config: Optional[Dict] = None
    ):
        """
        Args:
            model_path: path ‡∏Ç‡∏≠‡∏á YOLO model (default ‡∏à‡∏≤‡∏Å settings)
            conf_threshold: confidence threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö detection
            use_gemini: ‡πÉ‡∏ä‡πâ Gemini OCR ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gemini_config: custom config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini
        """
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å settings ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏
        model_path_str = model_path or settings.MODEL_PATH
        # Resolve relative path from project root
        if not Path(model_path_str).is_absolute():
            project_root = Path(__file__).parent.parent
            self.model_path = str(project_root / model_path_str)
        else:
            self.model_path = model_path_str
        self.conf_threshold = conf_threshold or settings.CONFIDENCE_THRESHOLD
        self.use_gemini = use_gemini
        
        # ‡πÇ‡∏´‡∏•‡∏î YOLO model
        logger.info("üîÑ Loading YOLOv11 License Plate Model...")
        logger.info(f"   Path: {self.model_path}")
        
        if not Path(self.model_path).exists():
            raise FileNotFoundError(
                f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö model file: {self.model_path}\n"
                f"   ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô: bash download_model.sh\n"
            )

        self.model = YOLO(self.model_path)
        logger.info("‚úÖ YOLO model loaded successfully")

        # Initialize Gemini OCR
        self.ocr = None
        if self.use_gemini:
            self._initialize_gemini(gemini_config)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á output directories
        settings.create_output_dirs()
        
        # üÜï ‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        self._load_thai_font()

        logger.info(f"‚úÖ Detector ready (Gemini OCR: {'enabled' if self.use_gemini else 'disabled'})")

    def _load_thai_font(self):
        """
        üÜï ‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        
        ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå:
        1. /usr/share/fonts/truetype/thai/ (Linux)
        2. C:/Windows/Fonts/ (Windows)
        3. /System/Library/Fonts/ (macOS)
        4. DejaVuSans (fallback ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢)
        """
        self.thai_font = None
        self.thai_font_size = 20
        
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏´‡∏≤
        thai_fonts = [
            # Linux
            "/usr/share/fonts/truetype/thai/Sarabun-Regular.ttf",
            "/usr/share/fonts/truetype/thai/Garuda.ttf",
            "/usr/share/fonts/truetype/thai/Loma.ttf",
            "/usr/share/fonts/truetype/thai/TlwgTypo.ttf",
            # Windows
            "C:/Windows/Fonts/THSarabunNew.ttf",
            "C:/Windows/Fonts/Tahoma.ttf",
            # macOS
            "/System/Library/Fonts/Thonburi.ttc",
            # Fallback
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        ]
        
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        for font_path in thai_fonts:
            if Path(font_path).exists():
                try:
                    self.thai_font = ImageFont.truetype(font_path, self.thai_font_size)
                    logger.info(f"‚úÖ Loaded Thai font: {font_path}")
                    return
                except Exception as e:
                    logger.debug(f"Failed to load font {font_path}: {e}")
                    continue
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÄ‡∏•‡∏¢ ‡πÉ‡∏ä‡πâ default font
        logger.warning("‚ö†Ô∏è No Thai font found, using default font (may not support Thai)")
        logger.warning("   To fix: install Thai fonts:")
        logger.warning("   Ubuntu: sudo apt-get install fonts-thai-tlwg")
        logger.warning("   Debian: sudo apt-get install fonts-tlwg-sarabun")
        self.thai_font = ImageFont.load_default()

    def _initialize_gemini(self, config: Optional[Dict] = None):
        """
        Initialize Gemini Vision API
        Args:
            config: Custom configuration
        """
        if not GEMINI_AVAILABLE:
            logger.error("‚ùå Gemini SDK not installed: pip install google-generativeai")
            self.use_gemini = False
            return

        # ‡∏î‡∏∂‡∏á config
        gemini_config = config or settings.get_ocr_config()
        api_key = gemini_config.get("api_key") or settings.GEMINI_API_KEY
        if not api_key:
            logger.error("‚ùå Gemini API key not found")
            logger.error("   Set GEMINI_API_KEY in .env file")
            self.use_gemini = False
            return

        try:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° use_image_url parameter
            self.ocr = GeminiOCR(
                api_key=api_key,
                model_name=gemini_config.get("model"),
                temperature=gemini_config.get("temperature", 0.1),
                max_retries=gemini_config.get("max_retries", 3),
                timeout=gemini_config.get("timeout", 30),
                use_image_url=gemini_config.get("use_image_url", True)
            )
            logger.info("‚úÖ Gemini OCR initialized")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Gemini: {e}")
            self.use_gemini = False

    def detect(
        self,
        image_path: str,
        save_image: bool = True,
        save_json: bool = True,
        use_ocr: Optional[bool] = None
    ) -> Dict:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô OCR)
        
        Args:
            image_path: path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
            save_image: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ annotate ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            save_json: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            use_ocr: ‡πÉ‡∏ä‡πâ OCR ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)
        
        Returns:
            dict ‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ OCR ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        should_use_ocr = use_ocr if use_ocr is not None else self.use_gemini
        
        # Validation
        if not Path(image_path).exists():
            raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {image_path}")
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {image_path}")
        
        logger.info(f"üîç Processing: {Path(image_path).name}")
        logger.info(f"   Image size: {image.shape[1]}x{image.shape[0]}")
        
        # ===== ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: YOLO Detection =====
        logger.info(f"   ‚ö° Running YOLO detection...")
        start_time = time.time()
        
        results = self.model.predict(
            source=image,
            conf=self.conf_threshold,
            save=False,
            verbose=False
        )
        
        detection_time = time.time() - start_time
        logger.info(f"   ‚úÖ Detection complete ({detection_time:.2f}s)")
        
        # ===== ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Process Results + OCR =====
        detections = self._process_detections(
            results[0], 
            image, 
            should_use_ocr,
            image_path
        )
        
        logger.info(f"   üìä Found {len(detections)} license plate(s)")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• OCR results
        for i, det in enumerate(detections, 1):
            if 'ocr' in det and det['ocr'].get('text'):
                ocr = det['ocr']
                logger.info(f"      Plate {i}: '{ocr['text']}' (conf: {ocr['confidence']:.2%})")
        
        # ===== ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Save Results =====
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = Path(image_path).stem
        
        output_data = {
            "input_path": image_path,
            "timestamp": timestamp,
            "detections": detections,
            "total_plates": len(detections),
            "processing_time": {
                "detection": detection_time,
                "total": time.time() - start_time
            },
            "model": {
                "yolo": self.model_path,
                "ocr": "gemini" if should_use_ocr else "none"
            }
        }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
        if save_image and len(detections) > 0:
            annotated_image = self._draw_annotations(image.copy(), detections)
            image_output_path = f"{settings.OUTPUT_IMAGE_DIR}/{filename}_{timestamp}.jpg"
            cv2.imwrite(image_output_path, annotated_image)
            output_data["output_image_path"] = image_output_path
            logger.info(f"   üíæ Saved image: {image_output_path}")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å JSON
        if save_json:
            json_output_path = f"{settings.OUTPUT_JSON_DIR}/{filename}_{timestamp}.json"
            with open(json_output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            output_data["output_json_path"] = json_output_path
            logger.info(f"   üíæ Saved JSON: {json_output_path}")
        
        logger.info(f"   ‚úÖ Processing complete\n")

        # Send result to Firestore
        try:
            from app.firestore_repository import FirestoreRepository
            repo = FirestoreRepository()
            repo.save_license_plate(output_data)
            logger.info("   üöÄ Sent detection result to Firestore.")
        except Exception as e:
            logger.error(f"   ‚ùå Failed to send result to Firestore: {e}")

        return output_data
    
    def _process_detections(
        self,
        yolo_result,
        image: np.ndarray,
        use_ocr: bool,
        image_path: str
    ) -> List[Dict]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å YOLO ‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô OCR
        
        Args:
            yolo_result: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å YOLO
            image: ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            use_ocr: ‡πÉ‡∏ä‡πâ OCR ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            image_path: path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        
        Returns:
            List of detection dictionaries
        """
        detections = []
        
        if yolo_result.boxes is None or len(yolo_result.boxes) == 0:
            logger.warning(f"   ‚ö†Ô∏è  No license plates detected")
            return detections
        
        logger.info(f"   üéØ Processing {len(yolo_result.boxes)} detection(s)...")
        
        for i, box in enumerate(yolo_result.boxes, 1):
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• bounding box
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            confidence = float(box.conf[0].cpu().numpy())
            class_id = int(box.cls[0].cpu().numpy())
            class_name = yolo_result.names[class_id]
            
            bbox = {
                "x1": float(x1),
                "y1": float(y1),
                "x2": float(x2),
                "y2": float(y2),
                "width": float(x2 - x1),
                "height": float(y2 - y1)
            }
            
            detection = {
                "detection_id": i,
                "bbox": bbox,
                "confidence": confidence,
                "class_id": class_id,
                "class_name": class_name
            }
            
            # ‡∏≠‡πà‡∏≤‡∏ô OCR ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
            if use_ocr and self.ocr:
                logger.info(f"ü§ñ Reading text from plate {i}...")
                ocr_result = self._read_plate_ocr(image, bbox, i, image_path)
                detection["ocr"] = ocr_result
                
                if ocr_result.get('text'):
                    logger.info(f"‚úÖ '{ocr_result['text']}'")
                else:
                    logger.info(f"‚úó No text detected")
            
            detections.append(detection)
        
        return detections
    
    def _read_plate_ocr(
        self,
        image: np.ndarray,
        bbox: Dict[str, float],
        detection_id: int,
        image_path: str
    ) -> Dict:
        """
        ‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Gemini
        
        Args:
            image: ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            bbox: bounding box ‡∏Ç‡∏≠‡∏á‡∏õ‡πâ‡∏≤‡∏¢
            detection_id: ID ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
            image_path: path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        
        Returns:
            OCR result dictionary
        """
        # Crop ‡∏†‡∏≤‡∏û‡∏õ‡πâ‡∏≤‡∏¢
        x1, y1 = int(bbox["x1"]), int(bbox["y1"])
        x2, y2 = int(bbox["x2"]), int(bbox["y2"])
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (5 pixels)
        padding = 5
        x1 = max(0, x1 - padding)
        y1 = max(0, y1 - padding)
        x2 = min(image.shape[1], x2 + padding)
        y2 = min(image.shape[0], y2 + padding)
        
        plate_img = image[y1:y2, x1:x2].copy()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ crop ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if plate_img.size == 0:
            return {
                "text": "",
                "confidence": 0.0,
                "engine": "gemini",
                "error": "Failed to crop image"
            }
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini OCR
        try:
            result = self.ocr.read_text(
                plate_img, 
                language="both",
                detection_id=detection_id,
                original_filename=Path(image_path).name
            )
            
            return {
                "text": result.get("text", ""),
                "confidence": result.get("confidence", 0.0),
                "engine": "gemini",
                "model": result.get("model", "unknown"),
                "processing_time": result.get("processing_time", 0),
                "raw_response": result.get("raw_response", ""),
                "mode": result.get("mode", "unknown"),
                "image_path": result.get("image_path", "")
            }
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è OCR error: {e}")
            return {
                "text": "",
                "confidence": 0.0,
                "engine": "gemini",
                "error": str(e)
            }
    
    def _draw_annotations(
        self,
        image: np.ndarray,
        detections: List[Dict]
    ) -> np.ndarray:
        """
        üÜï ‡∏ß‡∏≤‡∏î bounding box ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° OCR ‡∏ö‡∏ô‡∏†‡∏≤‡∏û (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
        
        Args:
            image: ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            detections: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        
        Returns:
            ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏î annotation ‡πÅ‡∏•‡πâ‡∏ß
        """
        # ‡πÅ‡∏õ‡∏•‡∏á OpenCV (BGR) ‡πÄ‡∏õ‡πá‡∏ô PIL (RGB)
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        for det in detections:
            bbox = det["bbox"]
            x1, y1 = int(bbox["x1"]), int(bbox["y1"])
            x2, y2 = int(bbox["x2"]), int(bbox["y2"])
            
            # ‡∏™‡∏µ: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ñ‡πâ‡∏≤‡∏°‡∏µ OCR text, ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            has_text = det.get("ocr", {}).get("text", "")
            color = (0, 255, 0) if has_text else (255, 255, 0)  # RGB
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö (‡πÉ‡∏ä‡πâ PIL)
            draw.rectangle([(x1, y1), (x2, y2)], outline=color, width=3)
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° labels
            labels = []
            
            # Label 1: Detection info
            det_conf = det['confidence']
            labels.append(f"Plate: {det_conf:.2%}")
            
            # Label 2: OCR text (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            if 'ocr' in det:
                ocr = det['ocr']
                ocr_text = ocr.get('text', '')
                ocr_conf = ocr.get('confidence', 0)
                ocr_mode = ocr.get('mode', 'unknown')
                
                if ocr_text:
                    labels.append(f"Text: {ocr_text}")  # üÜï ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß!
                    labels.append(f"OCR: {ocr_conf:.2%} ({ocr_mode})")
                else:
                    labels.append(f"OCR: No text")
            
            # ‡∏ß‡∏≤‡∏î labels ‡∏î‡πâ‡∏ß‡∏¢ PIL (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
            y_offset = y1
            
            for label in labels:
                # ‡∏ß‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î text
                bbox_text = draw.textbbox((0, 0), label, font=self.thai_font)
                label_w = bbox_text[2] - bbox_text[0]
                label_h = bbox_text[3] - bbox_text[1]
                
                # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á
                draw.rectangle(
                    [(x1, y_offset - label_h - 10), (x1 + label_w + 10, y_offset)],
                    fill=color
                )
                
                # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏™‡∏µ‡∏î‡∏≥)
                draw.text(
                    (x1 + 5, y_offset - label_h - 5),
                    label,
                    fill=(0, 0, 0),
                    font=self.thai_font
                )
                
                y_offset -= (label_h + 15)
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô OpenCV (RGB -> BGR)
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    
    def batch_detect(
        self,
        image_paths: List[str],
        save_image: bool = True,
        save_json: bool = True
    ) -> List[Dict]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
        
        Args:
            image_paths: list ‡∏Ç‡∏≠‡∏á path ‡∏†‡∏≤‡∏û
            save_image: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
            save_json: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å JSON
        
        Returns:
            List of detection results
        """
        logger.info("=" * 70)
        logger.info(f"üöÄ Batch Processing: {len(image_paths)} images")
        logger.info("=" * 70)
        
        results = []
        total_plates = 0
        successful = 0
        failed = 0
        
        start_time = time.time()
        
        for i, img_path in enumerate(image_paths, 1):
            logger.info(f"\n[{i}/{len(image_paths)}] Processing: {img_path}")
            
            try:
                result = self.detect(img_path, save_image, save_json)
                results.append(result)
                
                plates_found = result['total_plates']
                total_plates += plates_found
                successful += 1
                
            except Exception as e:
                logger.warning(f"   ‚ùå Error: {e}")
                results.append({
                    "error": str(e),
                    "path": img_path
                })
                failed += 1
        
        total_time = time.time() - start_time
        logger.info(f"\n‚úÖ Batch processing complete")
        logger.info(f"   Total images: {len(image_paths)}")
        logger.info(f"   Successful: {successful}")
        logger.info(f"   Failed: {failed}")
        logger.info(f"   Total plates detected: {total_plates}")
        logger.info(f"   Total time: {total_time:.2f}s")
        
        return results